{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b67d26-2274-4eb5-bd7e-0b3092924a9c",
   "metadata": {},
   "source": [
    "# PyHawaii Lightning Talk: Data Validation with Pandera\n",
    "- **Author:** Ka ªimi Kahihikolo, Data Scientist - Booz Allen Hamilton\n",
    "- **Date:** 2024/04/11\n",
    "- **Description:** Validating tabular data with the Python library: Pandera!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f5719e-a73a-46d2-9ef2-aa52cb503f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04bdd1-eb55-4d30-ab3c-0f0321eb34d3",
   "metadata": {},
   "source": [
    "## The Problem Statement\n",
    "\n",
    "As data scientists or engineers, we are often tasked with reading/processing external tabular data, such as csv, excel, etc. Depending on how this data is generated, or how delicate our downstream pipelines are, unforeseen changes in the source data may have dramatic downstream consequences in production environments.\n",
    "\n",
    "Suppose we had the following scenario - this data could be uploaded to our web app, pulled via some api, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196e23f4-ba39-42fe-afcd-7c9e23ddc1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Student_ID  Score\n",
       "0      ID_01      1\n",
       "1      ID_02      3\n",
       "2      ID_03      5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 'cleaning' the data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student_ID  Score\n",
       "0           1    0.0\n",
       "1           2    2.0\n",
       "2           3    4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "good_df = pd.DataFrame({\n",
    "    \"Student_ID\": [\"ID_01\", \"ID_02\", \"ID_03\"],\n",
    "    \"Score\": [1, 3, 5]\n",
    "})\n",
    "\n",
    "print(\"Original table\")\n",
    "display(good_df)\n",
    "\n",
    "# Split on _ and take 1th element\n",
    "good_df[\"Student_ID\"] = good_df[\"Student_ID\"].apply(lambda x: int(x.split(\"_\")[1]))\n",
    "# Subtract 1 and cast to float\n",
    "good_df[\"Score\"] = (good_df[\"Score\"] - 1).astype(float)\n",
    "\n",
    "print(\"After 'cleaning' the data\")\n",
    "display(good_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c86528-a292-4c31-8bd9-e04686345fb3",
   "metadata": {},
   "source": [
    "We just built our data transformation pipeline with assumptions, like Student_ID is always `ID_{2 digit number}`. However, what if our input data changed - for example, a human error or a change in an automated process.\n",
    "\n",
    "\n",
    "Here we define a bad dataframe which someone typod the Student ID and forgot to include the score column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d7eee0-e308-470d-be7f-cf71f62d58b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_FISH_DOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student_ID\n",
       "0        ID_01\n",
       "1        ID_02\n",
       "2  ID_FISH_DOG"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying apply the same transformation code\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'FISH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying apply the same transformation code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Split on _ and take 1th element\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m bad_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbad_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStudent_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Subtract 1 and cast to float\u001b[39;00m\n\u001b[1;32m     12\u001b[0m bad_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (bad_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying apply the same transformation code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Split on _ and take 1th element\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m bad_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m bad_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Subtract 1 and cast to float\u001b[39;00m\n\u001b[1;32m     12\u001b[0m bad_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (bad_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'FISH'"
     ]
    }
   ],
   "source": [
    "bad_df = pd.DataFrame({\n",
    "    \"Student_ID\": [\"ID_01\", \"ID_02\", \"ID_FISH_DOG\"],\n",
    "})\n",
    "\n",
    "print(\"Original table\")\n",
    "display(bad_df)\n",
    "\n",
    "print(\"Trying apply the same transformation code\")\n",
    "# Split on _ and take 1th element\n",
    "bad_df[\"Student_ID\"] = bad_df[\"Student_ID\"].apply(lambda x: int(x.split(\"_\")[1]))\n",
    "# Subtract 1 and cast to float\n",
    "bad_df[\"Score\"] = (bad_df[\"Score\"] - 1).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb4709-4b2b-4b2b-adf9-34cef0659696",
   "metadata": {},
   "source": [
    "If this happens in a production environment, you may face dire consequences! For example, completely breaking your web app/product, ruining the customer experience, or even worse corrupting your production database.\n",
    "\n",
    "Two questions:\n",
    "1. Can we check our data before even performing transformations?\n",
    "2. If the data doesn't conform to expectations, can we fail elegantly and log the reason?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2740def7-1d33-4596-ad3c-3d03fb1b3bc1",
   "metadata": {},
   "source": [
    "## Pandera to the Rescue!\n",
    "\n",
    "[Pandera](https://pandera.readthedocs.io/en/stable/index.html) is an open-source project which provides a convenient SDK to perform data validation on dataframe-like objects.\n",
    "\n",
    "Easy to install python library:\n",
    "```\n",
    "pip install pandera\n",
    "```\n",
    "\n",
    "Optional extras:\n",
    "```\n",
    "pip install pandera[hypotheses]  # hypothesis checks\n",
    "pip install pandera[io]          # yaml/script schema io utilities\n",
    "pip install pandera[strategies]  # data synthesis strategies\n",
    "pip install pandera[mypy]        # enable static type-linting of pandas\n",
    "pip install pandera[fastapi]     # fastapi integration\n",
    "pip install pandera[dask]        # validate dask dataframes\n",
    "pip install pandera[pyspark]     # validate pyspark dataframes\n",
    "pip install pandera[modin]       # validate modin dataframes\n",
    "pip install pandera[modin-ray]   # validate modin dataframes with ray\n",
    "pip install pandera[modin-dask]  # validate modin dataframes with dask\n",
    "pip install pandera[geopandas]   # validate geopandas geodataframes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db65d36d-72f1-4208-93f0-339677a31366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_FISH_DOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student_ID\n",
       "0        ID_01\n",
       "1        ID_02\n",
       "2  ID_FISH_DOG"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in the Pandera library\n",
    "import pandera as pa\n",
    "\n",
    "# Example bad data\n",
    "bad_df = pd.DataFrame({\n",
    "    \"Student_ID\": [\"ID_01\", \"ID_02\", \"ID_FISH_DOG\"],\n",
    "})\n",
    "print(\"Bad data\")\n",
    "display(bad_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e523a-ea56-4f10-942a-89140a75e852",
   "metadata": {},
   "source": [
    "### Simple Data Type Check\n",
    "\n",
    "Let's just check if the data types of the columns are right and if the columns are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7036d238-36cc-4e12-ab2d-6695395aed81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_schema = pa.DataFrameSchema({\n",
    "    \"Student_ID\": pa.Column(str, required=True),\n",
    "    \"Score\": pa.Column(int, required=True),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea1374a-adeb-4224-86f2-c96d7ea251bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate bad data\n"
     ]
    },
    {
     "ename": "SchemaError",
     "evalue": "column 'Score' not in dataframe. Columns in dataframe: ['Student_ID']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSchemaError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidate bad data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m display(\u001b[43msimple_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbad_df\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandera/api/pandas/container.py:375\u001b[0m, in \u001b[0;36mDataFrameSchema.validate\u001b[0;34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m    363\u001b[0m     check_obj \u001b[38;5;241m=\u001b[39m check_obj\u001b[38;5;241m.\u001b[39mmap_partitions(  \u001b[38;5;66;03m# type: ignore [operator]\u001b[39;00m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate,\n\u001b[1;32m    365\u001b[0m         head\u001b[38;5;241m=\u001b[39mhead,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m         meta\u001b[38;5;241m=\u001b[39mcheck_obj,\n\u001b[1;32m    372\u001b[0m     )\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m check_obj\u001b[38;5;241m.\u001b[39mpandera\u001b[38;5;241m.\u001b[39madd_schema(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandera/api/pandas/container.py:404\u001b[0m, in \u001b[0;36mDataFrameSchema._validate\u001b[0;34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_inferred:\n\u001b[1;32m    396\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is an inferred schema that hasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt been \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodified. It\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms recommended that you refine the schema \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    402\u001b[0m     )\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandera/backends/pandas/container.py:100\u001b[0m, in \u001b[0;36mDataFrameSchemaBackend.validate\u001b[0;34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[0m\n\u001b[1;32m     95\u001b[0m components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect_schema_components(\n\u001b[1;32m     96\u001b[0m     check_obj, schema, column_info\n\u001b[1;32m     97\u001b[0m )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# run the checks\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m error_handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_checks_and_handle_errors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_handler\u001b[38;5;241m.\u001b[39mcollected_errors:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_invalid_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandera/backends/pandas/container.py:175\u001b[0m, in \u001b[0;36mDataFrameSchemaBackend.run_checks_and_handle_errors\u001b[0;34m(self, error_handler, schema, check_obj, column_info, sample, components, lazy, head, tail, random_state)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m             error \u001b[38;5;241m=\u001b[39m SchemaError(\n\u001b[1;32m    166\u001b[0m                 schema,\n\u001b[1;32m    167\u001b[0m                 data\u001b[38;5;241m=\u001b[39mcheck_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 reason_code\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mreason_code,\n\u001b[1;32m    174\u001b[0m             )\n\u001b[0;32m--> 175\u001b[0m         \u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreason_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreason_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_exc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_handler\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandera/api/base/error_handler.py:54\u001b[0m, in \u001b[0;36mErrorHandler.collect_error\u001b[0;34m(self, error_type, reason_code, schema_error, original_exc)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Collect schema error, raising exception if lazy is False.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m:param error_type: type of error\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m:param reason_code: string representing reason for error\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m:param schema_error: ``SchemaError`` object.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m schema_error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moriginal_exc\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# delete data of validated object from SchemaError object to prevent\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# storing copies of the validated DataFrame/Series for every\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# SchemaError collected.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema_error, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mSchemaError\u001b[0m: column 'Score' not in dataframe. Columns in dataframe: ['Student_ID']"
     ]
    }
   ],
   "source": [
    "print(\"Validate bad data\")\n",
    "display(simple_schema.validate(bad_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89459232-8513-457d-9e84-e40dcfbd99bd",
   "metadata": {},
   "source": [
    "### Making it more robust with checks\n",
    "\n",
    "Let's apply slighlty more rigorous checks to make sure the data follows our expectations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1811312-5b84-495b-9fc3-4ed906222f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_robust = pa.DataFrameSchema({\n",
    "    \"Student_ID\": pa.Column(\n",
    "        str,\n",
    "        required=True,\n",
    "        checks=[\n",
    "            # Apply regex match\n",
    "            pa.Check.str_matches(\"ID_[0-9]{2}\")\n",
    "        ]\n",
    "    ),\n",
    "    \"Score\": pa.Column(\n",
    "        int,\n",
    "        required=True,\n",
    "        checks=[\n",
    "            # Less than or equal to 5\n",
    "            pa.Check.le(5),\n",
    "            # Greater than 0\n",
    "            pa.Check.gt(0)\n",
    "        ]\n",
    "    ),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a626976-5dcb-4f26-8455-650ac38a0069",
   "metadata": {},
   "source": [
    "When we validate our data, let's also have Python create a nice JSON representation of the error for logging purposes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62073df7-bdab-48e4-9f36-b0fcff0e403f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"SCHEMA\": {\n",
      "        \"COLUMN_NOT_IN_DATAFRAME\": [\n",
      "            {\n",
      "                \"schema\": null,\n",
      "                \"column\": null,\n",
      "                \"check\": \"column_in_dataframe\",\n",
      "                \"error\": \"column 'Score' not in dataframe. Columns in dataframe: ['Student_ID']\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"DATA\": {\n",
      "        \"DATAFRAME_CHECK\": [\n",
      "            {\n",
      "                \"schema\": null,\n",
      "                \"column\": \"Student_ID\",\n",
      "                \"check\": \"str_matches('ID_[0-9]{2}')\",\n",
      "                \"error\": \"Column 'Student_ID' failed element-wise validator number 0: str_matches('ID_[0-9]{2}') failure cases: ID_FISH_DOG\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    schema_robust.validate(bad_df, lazy=True)\n",
    "except pa.errors.SchemaErrors as e:\n",
    "    print(json.dumps(e.message, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4d2b1-20e6-40c0-a204-a7f7acab0863",
   "metadata": {},
   "source": [
    "You can find a full list of supported checks on their documentation: https://pandera.readthedocs.io/en/stable/checks.html\n",
    "\n",
    "What this means:\n",
    "- Data engineers can build these checks at the beginning of your data pipelines and handle the errors accordingly so your production environment doesn't break.\n",
    "- Upon error, record WHY it failed so you can fix the issue later!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b4851-896b-4ec5-bb99-387b4a5495cc",
   "metadata": {},
   "source": [
    "## Bonus: Synthetic Data Generation\n",
    "\n",
    "Once you have your schema defined, it is really easy to tell Pandera to generate synthetic data for you! This is very useful for unit testing your code or developing code when you don't have access to the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "958e15b0-444f-4264-9e8a-dc85716cf3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New synthesized data!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_87</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Student_ID  Score\n",
       "0      ID_77      2\n",
       "1      ID_35      2\n",
       "2      ID_87      5\n",
       "3      ID_52      2\n",
       "4      ID_95      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema_robust = pa.DataFrameSchema({\n",
    "    \"Student_ID\": pa.Column(\n",
    "        str,\n",
    "        required=True,\n",
    "        checks=[\n",
    "            # Apply regex match\n",
    "            pa.Check.str_matches(\"ID_[0-9]{2}\")\n",
    "        ]\n",
    "    ),\n",
    "    \"Score\": pa.Column(\n",
    "        int,\n",
    "        required=True,\n",
    "        checks=[\n",
    "            # Less than or equal to 5\n",
    "            pa.Check.le(5),\n",
    "            # Greater than 0\n",
    "            pa.Check.gt(0)\n",
    "        ]\n",
    "    ),\n",
    "})\n",
    "\n",
    "print(\"New synthesized data!\")\n",
    "display(schema_robust.example(size=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749424c-a63f-497f-883f-cb3b9ad1995f",
   "metadata": {},
   "source": [
    "In summary, Pandera is great and you should check it out!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
